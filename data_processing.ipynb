{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from requests.exceptions import Timeout, ConnectionError\n",
    "from requests.packages.urllib3.exceptions import ReadTimeoutError\n",
    "import ssl\n",
    "from tweepy import TweepError\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data process for papi feature extraction output, change raw output into csv files, with 37 (number of features) columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./ContestData/papi_out/2020_output/pipeDK.txt\n",
      "./ContestData/papi_out/2020_output/pipeDK.csv\n",
      "9\n",
      "./ContestData/papi_out/2020_output/newfiberDK.txt\n",
      "./ContestData/papi_out/2020_output/newfiberDK.csv\n",
      "37\n",
      "./ContestData/papi_out/2020_output/visualDK.txt\n",
      "./ContestData/papi_out/2020_output/visualDK.csv\n",
      "97\n",
      "./ContestData/papi_out/2020_output/messengerDK.txt\n",
      "./ContestData/papi_out/2020_output/messengerDK.csv\n",
      "46\n",
      "./ContestData/papi_out/2020_output/evolutionDK.txt\n",
      "./ContestData/papi_out/2020_output/evolutionDK.csv\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "dir_home = './ContestData/papi_out/'\n",
    "year = [\n",
    "#     '2013', \n",
    "#     '2014', \n",
    "#     '2019',\n",
    "#     '2015',\n",
    "    '2016',\n",
    "#     '2017',\n",
    "#     '2018',\n",
    "#     '2020',\n",
    "]\n",
    "header = ['PAPI_TOT_INS', 'PAPI_TOT_CYC', 'PAPI_L2_ICH', 'PAPI_L2_ICA', 'PAPI_L2_ICM', 'PAPI_L2_TCH', \n",
    "          'PAPI_L2_TCA', 'PAPI_L2_TCM', 'PAPI_L2_DCH', 'PAPI_L2_DCA', 'PAPI_L2_DCM', 'PAPI_L1_ICR', \n",
    "          'PAPI_L1_ICA', 'PAPI_L1_ICM', 'PAPI_L1_TCH', 'PAPI_L1_TCA', 'PAPI_L1_TCM', 'PAPI_L1_DCH', \n",
    "          'PAPI_L1_DCA', 'PAPI_L1_DCM', 'PAPI_TLB_DM', 'PAPI_TLB_IM', 'PAPI_TLB_TL', 'PAPI_STL_ICY', \n",
    "          'PAPI_HW_INT', 'PAPI_BR_TKN', 'PAPI_BR_MSP', 'PAPI_BR_INS', 'PAPI_VEC_INS', 'PAPI_RES_STL', \n",
    "          'PAPI_FML_INS', 'PAPI_FAD_INS', 'PAPI_FDV_INS', 'PAPI_FSQ_INS', 'PAPI_FP_OPS', 'PAPI_SP_OPS', 'PAPI_DP_OPS']\n",
    "# flag = True\n",
    "for y in year:\n",
    "#     if flag == False:\n",
    "#         break\n",
    "    dir_name = dir_home + y + '_output'\n",
    "    for root, _, files in os.walk(dir_name):\n",
    "        for file in files:\n",
    "#             if flag == False:\n",
    "#                 break\n",
    "            if '.txt' not in file:\n",
    "                continue\n",
    "            fin_name = dir_name + '/' + file\n",
    "            print(fin_name)\n",
    "            fout_name = dir_name + '/' + file[:-4] + '.csv'\n",
    "            print(fout_name)\n",
    "#             flag = False\n",
    "            mat = [[] for i in range(37)]\n",
    "            with open(fin_name) as fin:\n",
    "                with open(fout_name, 'w', newline = '') as fout:\n",
    "                    reader = csv.reader(fin)\n",
    "                    cnt = -1\n",
    "                    for row in reader:\n",
    "#                         print(row)\n",
    "                        if 'round of counting' in row[0]:\n",
    "#                             print(row)\n",
    "                            cnt += 1\n",
    "                        else:\n",
    "                            mat[cnt].append(row[0])\n",
    "                    exm_cnt = len(mat[0])\n",
    "                    print(exm_cnt)\n",
    "#                     print(mat)\n",
    "                    writer = csv.writer(fout)\n",
    "                    writer.writerow(header)\n",
    "                    rows = [[] for i in range(exm_cnt)]\n",
    "                    for i in range(len(mat)):\n",
    "                        for j in range(len(mat[0])):\n",
    "#                             print(i, j)\n",
    "                            rows[j].append(mat[i][j])\n",
    "                    writer.writerows(rows)           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge features (from papi) and labels (from gem5) into a single csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./ContestData/papi_out/finals2016-papi/\n",
      "['foreveryoungDK.csv', '.DS_Store', 'ceilingDK.csv', 'oilDK.csv', 'stringDK.csv', 'swapspaceDK.csv', 'marsDK.csv', 'puzzleDK.csv', 'branchDK.csv', 'clockDK.csv', 'balanceddietDK.csv']\n",
      "foreveryoung\n",
      "find match ./ContestData/papi_out/finals2016-papi/foreveryoungDK.csv ./ContestData/ACMFinalsSolutions/finals2016-tick/E-foreveryoung.tick\n",
      "./ContestData/ACMFinalsSolutions/finals2016-tick/E-foreveryoung.csv\n",
      "58 58\n",
      ".DS\n",
      "ceiling\n",
      "find match ./ContestData/papi_out/finals2016-papi/ceilingDK.csv ./ContestData/ACMFinalsSolutions/finals2016-tick/C-ceiling.tick\n",
      "./ContestData/ACMFinalsSolutions/finals2016-tick/C-ceiling.csv\n",
      "38 38\n",
      "oil\n",
      "find match ./ContestData/papi_out/finals2016-papi/oilDK.csv ./ContestData/ACMFinalsSolutions/finals2016-tick/G-oil.tick\n",
      "./ContestData/ACMFinalsSolutions/finals2016-tick/G-oil.csv\n",
      "36 36\n",
      "string\n",
      "find match ./ContestData/papi_out/finals2016-papi/stringDK.csv ./ContestData/ACMFinalsSolutions/finals2016-tick/L-string.tick\n",
      "./ContestData/ACMFinalsSolutions/finals2016-tick/L-string.csv\n",
      "103 103\n",
      "swapspace\n",
      "find match ./ContestData/papi_out/finals2016-papi/swapspaceDK.csv ./ContestData/ACMFinalsSolutions/finals2016-tick/M-swapspace.tick\n",
      "./ContestData/ACMFinalsSolutions/finals2016-tick/M-swapspace.csv\n",
      "27 27\n",
      "mars\n",
      "find match ./ContestData/papi_out/finals2016-papi/marsDK.csv ./ContestData/ACMFinalsSolutions/finals2016-tick/F-mars.tick\n",
      "./ContestData/ACMFinalsSolutions/finals2016-tick/F-mars.csv\n",
      "47 47\n",
      "puzzle\n",
      "find match ./ContestData/papi_out/finals2016-papi/puzzleDK.csv ./ContestData/ACMFinalsSolutions/finals2016-tick/H-puzzle.tick\n",
      "./ContestData/ACMFinalsSolutions/finals2016-tick/H-puzzle.csv\n",
      "59 59\n",
      "branch\n",
      "find match ./ContestData/papi_out/finals2016-papi/branchDK.csv ./ContestData/ACMFinalsSolutions/finals2016-tick/B-branch.tick\n",
      "./ContestData/ACMFinalsSolutions/finals2016-tick/B-branch.csv\n",
      "50 50\n",
      "clock\n",
      "find match ./ContestData/papi_out/finals2016-papi/clockDK.csv ./ContestData/ACMFinalsSolutions/finals2016-tick/D-clock.tick\n",
      "./ContestData/ACMFinalsSolutions/finals2016-tick/D-clock.csv\n",
      "35 35\n",
      "balanceddiet\n",
      "find match ./ContestData/papi_out/finals2016-papi/balanceddietDK.csv ./ContestData/ACMFinalsSolutions/finals2016-tick/A-balanceddiet.tick\n",
      "./ContestData/ACMFinalsSolutions/finals2016-tick/A-balanceddiet.csv\n",
      "81 81\n"
     ]
    }
   ],
   "source": [
    "# year = '2013'\n",
    "# padding = 2\n",
    "# year = '2014'\n",
    "# padding = 2 # B is 3\n",
    "# year = '2015'\n",
    "# padding = 0\n",
    "year = '2016'\n",
    "padding = 2\n",
    "# year = '2017'\n",
    "# padding = 0\n",
    "# year = '2018'\n",
    "# padding = 0\n",
    "# year = '2019'\n",
    "# padding = 0\n",
    "# year = '2020'\n",
    "# padding = 0\n",
    "\n",
    "srcdir_papi = './ContestData/papi_out/finals' + year + '-papi/'\n",
    "srcdir_gem = './ContestData/ACMFinalsSolutions/finals' + year + '-tick/'\n",
    "flag = True\n",
    "for root_p, _, files_p in os.walk(srcdir_papi):\n",
    "    print(root_p)\n",
    "    print(files_p)\n",
    "    for file_p in files_p:\n",
    "#         if flag == False:\n",
    "#             break\n",
    "        key = file_p[:-6] #TODO\n",
    "        print(key)\n",
    "        for root_g, _, files_g in os.walk(srcdir_gem):\n",
    "#             print(root_g)\n",
    "#             print(files_g)\n",
    "            for file_g in files_g:\n",
    "                if '.tick' not in file_g:\n",
    "                    continue\n",
    "                if key in file_g:\n",
    "#                     print('find match %s %s' % (file_p, file_g))\n",
    "                    file_name_papi = srcdir_papi + file_p\n",
    "                    file_name_gem = srcdir_gem + file_g\n",
    "                    print('find match %s %s' % (file_name_papi, file_name_gem))\n",
    "                    flag = False\n",
    "                    fout_name = srcdir_gem + file_g\n",
    "                    fout_name = fout_name[:-5] + '.csv'\n",
    "                    print(fout_name)\n",
    "                    with open(file_name_papi) as finpapi:\n",
    "                        with open(file_name_gem) as fingem:\n",
    "                            with open(fout_name, 'w', newline='') as fout:\n",
    "                                reader1 = csv.reader(finpapi)\n",
    "                                reader2 = csv.reader(fingem)\n",
    "                                writer = csv.writer(fout)\n",
    "                                header = next(reader1)\n",
    "                                header.append('label')\n",
    "    #                             print(header)\n",
    "                                writer.writerow(header)\n",
    "                                if padding == 2:\n",
    "                                    _ = next(reader1)\n",
    "                                    _ = next(reader1)\n",
    "                                rows1 = list(reader1)\n",
    "                                rows2 = list(reader2)\n",
    "                                print(len(rows1), len(rows2))\n",
    "                                assert(len(rows1) == len(rows2) \n",
    "#                                        or len(rows1) == len(rows2)-1\n",
    "                                      )\n",
    "                                for i in range(len(rows1)):\n",
    "                                    if len(rows2[i]) == 0:\n",
    "                                        continue\n",
    "                                    else:\n",
    "                                        comb_row = rows1[i]\n",
    "                                        comb_row.append(rows2[i][0])\n",
    "#                                         print(comb_row)\n",
    "                                        writer.writerow(comb_row)\n",
    "                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge csv files for multiple problems in a single year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./ContestData/train2016_all.csv\n"
     ]
    }
   ],
   "source": [
    "dir_home = './ContestData/'\n",
    "year = [\n",
    "#     '2013', \n",
    "#     '2014', \n",
    "#     '2015',\n",
    "    '2016',\n",
    "#     '2017',\n",
    "#     '2018',\n",
    "#     '2019',\n",
    "#     '2020',\n",
    "]\n",
    "for y in year:\n",
    "    first = True\n",
    "    dir_name = dir_home + 'train' + y + '/'\n",
    "    fout_name = dir_home + 'train' + y + '_all.csv'\n",
    "    print(fout_name)\n",
    "    with open(fout_name, 'w', newline='') as fout:\n",
    "        writer = csv.writer(fout)\n",
    "        for root, _, files in os.walk(dir_name):\n",
    "            print(root)\n",
    "            print(files)\n",
    "            for file in files:\n",
    "                file_name = dir_name + file\n",
    "                print(file_name)\n",
    "                with open(file_name) as fin:\n",
    "                    reader = csv.reader(fin)\n",
    "                    header = next(reader)\n",
    "                    if first:\n",
    "                        writer.writerow(header)\n",
    "                        first = False\n",
    "                    for row in reader:\n",
    "                        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate whole dataset by merging csv files from each year (2013-2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./ContestData/train2013_all.csv\n",
      "./ContestData/train2014_all.csv\n",
      "./ContestData/train2015_all.csv\n",
      "./ContestData/train2017_all.csv\n",
      "./ContestData/train2018_all.csv\n",
      "./ContestData/train2019_all.csv\n"
     ]
    }
   ],
   "source": [
    "dir_home = './ContestData/'\n",
    "year = [\n",
    "    '2013', \n",
    "    '2014', \n",
    "    '2015',\n",
    "#     '2016',\n",
    "    '2017',\n",
    "    '2018',\n",
    "    '2019',\n",
    "#     '2020',\n",
    "]\n",
    "first = True\n",
    "fout_name = dir_home + 'train_all.csv'\n",
    "with open(fout_name, 'w', newline='') as fout:\n",
    "    writer = csv.writer(fout)\n",
    "    for y in year:\n",
    "        fin_name = dir_home + 'train' + y + '_all.csv'\n",
    "        print(fin_name)\n",
    "        with open(fin_name) as fin:\n",
    "            reader = csv.reader(fin)\n",
    "            header = next(reader)\n",
    "            if first:\n",
    "                writer.writerow(header)\n",
    "                first = False\n",
    "            for row in reader:\n",
    "                writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1262, 38) (126, 38) (1136, 38)\n"
     ]
    }
   ],
   "source": [
    "file = './ContestData/train_all.csv'\n",
    "fout_train = './ContestData/train.csv'\n",
    "fout_test = './ContestData/test.csv'\n",
    "\n",
    "df = pd.read_csv(file)\n",
    "# df.drop_duplicates(keep='first', inplace=True)\n",
    "df = df.sample(frac=1.0)\n",
    "cut_idx = int(round(0.1 * df.shape[0]))\n",
    "df_test, df_train = df.iloc[:cut_idx], df.iloc[cut_idx:]\n",
    "df_train.to_csv(fout_train)\n",
    "df_test.to_csv(fout_test)\n",
    "print(df.shape, df_test.shape, df_train.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
